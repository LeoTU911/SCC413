{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyNWDXXBO1SeesdajHzP/KO9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoTU911/SCC413/blob/main/cycleGAN_1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dominate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUBwfCRA_ina",
        "outputId": "9e8eac1a-98b2-4ba8-dd79-81a8cc48f903"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dominate\n",
            "  Downloading dominate-2.7.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install visdom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SDd0BUIBZib",
        "outputId": "4b7f4307-94a0-441a-b56a-f2e4b4f1e1ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting visdom\n",
            "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.8/dist-packages (from visdom) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from visdom) (1.7.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from visdom) (2.25.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.8/dist-packages (from visdom) (6.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from visdom) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from visdom) (3.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from visdom) (7.1.2)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->visdom) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->visdom) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->visdom) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->visdom) (1.24.3)\n",
            "Building wheels for collected packages: visdom\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408217 sha256=c52a77cf6eaa26e39bcd4d291a76d38e5d34c94a430196ceee851ae772352c72\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/b1/fc/b05c2c1930a412f01bd07dacaeb5fd8cc4bcccf71c835b0281\n",
            "Successfully built visdom\n",
            "Installing collected packages: websocket-client, jsonpointer, jsonpatch, visdom\n",
            "Successfully installed jsonpatch-1.32 jsonpointer-2.3 visdom-0.2.4 websocket-client-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dominate\n",
        "import visdom"
      ],
      "metadata": {
        "id": "HUe3ULlg_pts"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJk9Crj_6zY8",
        "outputId": "9cb910df-f509-4804-8a5b-7c1b8663af2c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n",
            "remote: Enumerating objects: 2508, done.\u001b[K\n",
            "remote: Total 2508 (delta 0), reused 0 (delta 0), pack-reused 2508\u001b[K\n",
            "Receiving objects: 100% (2508/2508), 8.19 MiB | 12.73 MiB/s, done.\n",
            "Resolving deltas: 100% (1573/1573), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/pytorch-CycleGAN-and-pix2pix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBBx5z4u7Lvo",
        "outputId": "73f847d7-7289-4141-c640-353b4fc0de14"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch-CycleGAN-and-pix2pix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!./scripts/train_cyclegan.sh\n",
        "!python train.py --dataroot ./datasets/photo2sketch/ --name ph2sk_cyclegan --model cycle_gan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztIIUvRI7z23",
        "outputId": "361df959-b4b1-43c4-8d0d-717a341b7146"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/photo2sketch/      \t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: 1                             \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cycle_gan                     \n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: ph2sk_cyclegan                \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The number of training images = 88\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [CycleGANModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 11.378 M\n",
            "[Network G_B] Total number of parameters : 11.378 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "Setting up a new session...\n",
            "Exception in user code:\n",
            "------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connection.py\", line 158, in _new_conn\n",
            "    conn = connection.create_connection(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/util/connection.py\", line 80, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/util/connection.py\", line 70, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 597, in urlopen\n",
            "    httplib_response = self._make_request(conn, method, url,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 354, in _make_request\n",
            "    conn.request(method, url, **httplib_request_kw)\n",
            "  File \"/usr/lib/python3.8/http/client.py\", line 1256, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.8/http/client.py\", line 1302, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.8/http/client.py\", line 1251, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.8/http/client.py\", line 1011, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.8/http/client.py\", line 951, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connection.py\", line 181, in connect\n",
            "    conn = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connection.py\", line 167, in _new_conn\n",
            "    raise NewConnectionError(\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f3d0037bcd0>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/requests/adapters.py\", line 439, in send\n",
            "    resp = conn.urlopen(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 637, in urlopen\n",
            "    retries = retries.increment(method, url, error=e, _pool=self,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/util/retry.py\", line 399, in increment\n",
            "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f3d0037bcd0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/visdom/__init__.py\", line 756, in _send\n",
            "    return self._handle_post(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/visdom/__init__.py\", line 720, in _handle_post\n",
            "    r = self.session.post(url, data=data)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/requests/sessions.py\", line 590, in post\n",
            "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/requests/sessions.py\", line 542, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/requests/sessions.py\", line 655, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/requests/adapters.py\", line 516, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f3d0037bcd0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
            "\n",
            "\n",
            "Could not connect to Visdom server. \n",
            " Trying to start a server....\n",
            "Command: /usr/bin/python3 -m visdom.server -p 8097 &>/dev/null &\n",
            "create web directory ./checkpoints/ph2sk_cyclegan/web...\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "[Errno 99] Cannot assign requested address\n",
            "on_close() takes 1 positional argument but 3 were given\n",
            "End of epoch 1 / 200 \t Time Taken: 49 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 12, time: 0.523, data: 0.240) D_A: 0.552 G_A: 0.585 cycle_A: 1.080 idt_A: 0.408 D_B: 0.266 G_B: 0.417 cycle_B: 0.905 idt_B: 0.479 \n",
            "End of epoch 2 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 24, time: 0.531, data: 0.002) D_A: 0.245 G_A: 0.175 cycle_A: 1.431 idt_A: 0.280 D_B: 0.184 G_B: 0.370 cycle_B: 0.635 idt_B: 0.671 \n",
            "End of epoch 3 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 36, time: 0.536, data: 0.002) D_A: 0.231 G_A: 0.223 cycle_A: 1.109 idt_A: 0.295 D_B: 0.132 G_B: 0.325 cycle_B: 0.652 idt_B: 0.488 \n",
            "End of epoch 4 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 48, time: 0.866, data: 0.002) D_A: 0.219 G_A: 0.297 cycle_A: 0.865 idt_A: 0.376 D_B: 0.223 G_B: 0.430 cycle_B: 0.888 idt_B: 0.412 \n",
            "saving the model at the end of epoch 5, iters 440\n",
            "End of epoch 5 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 60, time: 0.534, data: 0.002) D_A: 0.274 G_A: 0.283 cycle_A: 1.644 idt_A: 0.347 D_B: 0.211 G_B: 0.313 cycle_B: 0.892 idt_B: 0.781 \n",
            "End of epoch 6 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 72, time: 0.527, data: 0.002) D_A: 0.317 G_A: 0.398 cycle_A: 0.845 idt_A: 0.246 D_B: 0.167 G_B: 0.458 cycle_B: 0.607 idt_B: 0.411 \n",
            "End of epoch 7 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 84, time: 0.532, data: 0.002) D_A: 0.249 G_A: 0.383 cycle_A: 0.677 idt_A: 0.392 D_B: 0.304 G_B: 0.127 cycle_B: 0.809 idt_B: 0.277 \n",
            "End of epoch 8 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 9 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 8, time: 0.943, data: 0.002) D_A: 0.432 G_A: 0.305 cycle_A: 0.714 idt_A: 0.367 D_B: 0.235 G_B: 0.226 cycle_B: 0.760 idt_B: 0.306 \n",
            "saving the model at the end of epoch 10, iters 880\n",
            "End of epoch 10 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 20, time: 0.536, data: 0.009) D_A: 0.225 G_A: 0.391 cycle_A: 1.150 idt_A: 0.325 D_B: 0.253 G_B: 0.299 cycle_B: 0.739 idt_B: 0.487 \n",
            "End of epoch 11 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 32, time: 0.529, data: 0.002) D_A: 0.192 G_A: 0.299 cycle_A: 0.826 idt_A: 0.240 D_B: 0.330 G_B: 0.356 cycle_B: 0.561 idt_B: 0.375 \n",
            "End of epoch 12 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 44, time: 0.529, data: 0.002) D_A: 0.298 G_A: 0.160 cycle_A: 0.565 idt_A: 0.184 D_B: 0.220 G_B: 0.197 cycle_B: 0.442 idt_B: 0.248 \n",
            "End of epoch 13 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 56, time: 0.939, data: 0.002) D_A: 0.123 G_A: 0.223 cycle_A: 1.146 idt_A: 0.261 D_B: 0.265 G_B: 0.510 cycle_B: 0.582 idt_B: 0.521 \n",
            "End of epoch 14 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 68, time: 0.533, data: 0.002) D_A: 0.270 G_A: 0.214 cycle_A: 1.328 idt_A: 0.237 D_B: 0.303 G_B: 0.266 cycle_B: 0.551 idt_B: 0.560 \n",
            "saving the model at the end of epoch 15, iters 1320\n",
            "End of epoch 15 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 80, time: 0.531, data: 0.002) D_A: 0.196 G_A: 0.126 cycle_A: 0.661 idt_A: 0.209 D_B: 0.702 G_B: 1.019 cycle_B: 0.508 idt_B: 0.326 \n",
            "End of epoch 16 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 17 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 4, time: 0.530, data: 0.002) D_A: 0.292 G_A: 0.157 cycle_A: 0.751 idt_A: 0.229 D_B: 0.248 G_B: 0.301 cycle_B: 0.539 idt_B: 0.329 \n",
            "End of epoch 18 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 16, time: 0.949, data: 0.001) D_A: 0.239 G_A: 0.536 cycle_A: 1.016 idt_A: 0.221 D_B: 0.179 G_B: 0.344 cycle_B: 0.471 idt_B: 0.450 \n",
            "End of epoch 19 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 28, time: 0.533, data: 0.002) D_A: 0.294 G_A: 0.424 cycle_A: 0.859 idt_A: 0.161 D_B: 0.101 G_B: 0.611 cycle_B: 0.496 idt_B: 0.324 \n",
            "saving the model at the end of epoch 20, iters 1760\n",
            "End of epoch 20 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 40, time: 0.528, data: 0.009) D_A: 0.254 G_A: 0.258 cycle_A: 1.028 idt_A: 0.360 D_B: 0.092 G_B: 0.351 cycle_B: 0.785 idt_B: 0.453 \n",
            "End of epoch 21 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 52, time: 0.529, data: 0.002) D_A: 0.205 G_A: 0.408 cycle_A: 0.792 idt_A: 0.185 D_B: 0.148 G_B: 0.291 cycle_B: 0.460 idt_B: 0.344 \n",
            "End of epoch 22 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 64, time: 0.977, data: 0.002) D_A: 0.158 G_A: 0.415 cycle_A: 0.793 idt_A: 0.294 D_B: 0.162 G_B: 0.467 cycle_B: 0.721 idt_B: 0.295 \n",
            "End of epoch 23 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 76, time: 0.517, data: 0.006) D_A: 0.202 G_A: 0.414 cycle_A: 1.023 idt_A: 0.346 D_B: 0.245 G_B: 0.176 cycle_B: 0.743 idt_B: 0.433 \n",
            "End of epoch 24 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 88, time: 0.529, data: 0.002) D_A: 0.381 G_A: 0.206 cycle_A: 0.748 idt_A: 0.276 D_B: 0.287 G_B: 0.125 cycle_B: 0.575 idt_B: 0.265 \n",
            "saving the model at the end of epoch 25, iters 2200\n",
            "End of epoch 25 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 26 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 12, time: 0.528, data: 0.155) D_A: 0.384 G_A: 0.339 cycle_A: 2.662 idt_A: 0.306 D_B: 0.160 G_B: 0.408 cycle_B: 0.627 idt_B: 1.080 \n",
            "End of epoch 27 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 24, time: 1.088, data: 0.002) D_A: 0.208 G_A: 0.296 cycle_A: 0.829 idt_A: 0.245 D_B: 0.287 G_B: 0.158 cycle_B: 0.572 idt_B: 0.340 \n",
            "End of epoch 28 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 36, time: 0.531, data: 0.002) D_A: 0.273 G_A: 0.583 cycle_A: 0.691 idt_A: 0.563 D_B: 0.132 G_B: 0.804 cycle_B: 1.153 idt_B: 0.320 \n",
            "End of epoch 29 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 48, time: 0.528, data: 0.012) D_A: 0.100 G_A: 0.116 cycle_A: 0.749 idt_A: 0.170 D_B: 0.157 G_B: 0.369 cycle_B: 0.501 idt_B: 0.339 \n",
            "saving the model at the end of epoch 30, iters 2640\n",
            "End of epoch 30 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 60, time: 0.522, data: 0.011) D_A: 0.248 G_A: 0.458 cycle_A: 0.898 idt_A: 0.334 D_B: 0.720 G_B: 0.102 cycle_B: 0.825 idt_B: 0.319 \n",
            "End of epoch 31 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 72, time: 1.286, data: 0.009) D_A: 0.184 G_A: 0.326 cycle_A: 1.123 idt_A: 0.171 D_B: 0.156 G_B: 0.701 cycle_B: 0.441 idt_B: 0.514 \n",
            "End of epoch 32 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 84, time: 0.531, data: 0.014) D_A: 0.253 G_A: 0.146 cycle_A: 0.785 idt_A: 0.201 D_B: 0.200 G_B: 0.239 cycle_B: 0.523 idt_B: 0.391 \n",
            "End of epoch 33 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 34 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 8, time: 0.513, data: 0.002) D_A: 0.258 G_A: 0.238 cycle_A: 1.020 idt_A: 0.263 D_B: 0.161 G_B: 0.210 cycle_B: 0.634 idt_B: 0.418 \n",
            "saving the model at the end of epoch 35, iters 3080\n",
            "End of epoch 35 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 20, time: 0.526, data: 0.000) D_A: 0.074 G_A: 0.317 cycle_A: 1.132 idt_A: 0.213 D_B: 0.223 G_B: 0.286 cycle_B: 0.615 idt_B: 0.451 \n",
            "End of epoch 36 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 32, time: 1.220, data: 0.002) D_A: 0.208 G_A: 0.343 cycle_A: 0.697 idt_A: 0.160 D_B: 0.249 G_B: 0.158 cycle_B: 0.394 idt_B: 0.276 \n",
            "End of epoch 37 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 44, time: 0.526, data: 0.012) D_A: 0.223 G_A: 0.078 cycle_A: 0.708 idt_A: 0.196 D_B: 0.236 G_B: 0.280 cycle_B: 0.458 idt_B: 0.286 \n",
            "End of epoch 38 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 56, time: 0.523, data: 0.010) D_A: 0.182 G_A: 0.558 cycle_A: 0.539 idt_A: 0.200 D_B: 0.376 G_B: 0.639 cycle_B: 0.504 idt_B: 0.214 \n",
            "End of epoch 39 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 68, time: 0.519, data: 0.002) D_A: 0.178 G_A: 0.331 cycle_A: 0.664 idt_A: 0.194 D_B: 0.280 G_B: 0.468 cycle_B: 0.467 idt_B: 0.345 \n",
            "saving the model at the end of epoch 40, iters 3520\n",
            "End of epoch 40 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 80, time: 1.299, data: 0.002) D_A: 0.274 G_A: 0.573 cycle_A: 0.492 idt_A: 0.230 D_B: 0.301 G_B: 0.314 cycle_B: 0.536 idt_B: 0.178 \n",
            "End of epoch 41 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 42 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 4, time: 0.520, data: 0.002) D_A: 0.125 G_A: 0.169 cycle_A: 0.617 idt_A: 0.180 D_B: 0.195 G_B: 0.408 cycle_B: 0.427 idt_B: 0.257 \n",
            "End of epoch 43 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 16, time: 0.525, data: 0.007) D_A: 0.203 G_A: 0.305 cycle_A: 0.750 idt_A: 0.168 D_B: 0.120 G_B: 0.378 cycle_B: 0.409 idt_B: 0.303 \n",
            "End of epoch 44 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 28, time: 0.534, data: 0.002) D_A: 0.192 G_A: 0.355 cycle_A: 0.459 idt_A: 0.199 D_B: 0.224 G_B: 0.552 cycle_B: 0.446 idt_B: 0.199 \n",
            "saving the model at the end of epoch 45, iters 3960\n",
            "End of epoch 45 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 40, time: 1.307, data: 0.009) D_A: 0.249 G_A: 0.156 cycle_A: 0.796 idt_A: 0.170 D_B: 0.241 G_B: 0.224 cycle_B: 0.437 idt_B: 0.367 \n",
            "End of epoch 46 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 52, time: 0.533, data: 0.008) D_A: 0.140 G_A: 0.310 cycle_A: 0.923 idt_A: 0.165 D_B: 0.189 G_B: 0.269 cycle_B: 0.459 idt_B: 0.356 \n",
            "End of epoch 47 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 64, time: 0.537, data: 0.002) D_A: 0.286 G_A: 0.522 cycle_A: 0.755 idt_A: 0.229 D_B: 0.227 G_B: 0.285 cycle_B: 0.665 idt_B: 0.387 \n",
            "End of epoch 48 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 76, time: 0.531, data: 0.003) D_A: 0.150 G_A: 0.255 cycle_A: 0.727 idt_A: 0.214 D_B: 0.181 G_B: 0.575 cycle_B: 0.473 idt_B: 0.297 \n",
            "End of epoch 49 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 50, iters: 88, time: 1.160, data: 0.002) D_A: 0.277 G_A: 0.365 cycle_A: 0.589 idt_A: 0.201 D_B: 0.195 G_B: 0.282 cycle_B: 0.480 idt_B: 0.276 \n",
            "saving the model at the end of epoch 50, iters 4400\n",
            "End of epoch 50 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 51 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 52, iters: 12, time: 0.514, data: 0.278) D_A: 0.196 G_A: 0.123 cycle_A: 0.599 idt_A: 0.220 D_B: 0.163 G_B: 0.215 cycle_B: 0.572 idt_B: 0.259 \n",
            "End of epoch 52 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 53, iters: 24, time: 0.522, data: 0.002) D_A: 0.079 G_A: 0.493 cycle_A: 1.307 idt_A: 0.248 D_B: 0.163 G_B: 0.527 cycle_B: 0.629 idt_B: 0.538 \n",
            "End of epoch 53 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 54, iters: 36, time: 0.533, data: 0.002) D_A: 0.197 G_A: 0.361 cycle_A: 1.052 idt_A: 0.152 D_B: 0.191 G_B: 0.476 cycle_B: 0.400 idt_B: 0.362 \n",
            "End of epoch 54 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 55, iters: 48, time: 1.328, data: 0.002) D_A: 0.151 G_A: 0.383 cycle_A: 0.921 idt_A: 0.327 D_B: 0.268 G_B: 0.618 cycle_B: 0.682 idt_B: 0.456 \n",
            "saving the model at the end of epoch 55, iters 4840\n",
            "End of epoch 55 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 56, iters: 60, time: 0.525, data: 0.002) D_A: 0.256 G_A: 0.176 cycle_A: 0.755 idt_A: 0.230 D_B: 0.260 G_B: 0.296 cycle_B: 0.524 idt_B: 0.293 \n",
            "End of epoch 56 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 57, iters: 72, time: 0.526, data: 0.003) D_A: 0.125 G_A: 0.172 cycle_A: 0.728 idt_A: 0.177 D_B: 0.168 G_B: 0.506 cycle_B: 0.495 idt_B: 0.248 \n",
            "saving the latest model (epoch 57, total_iters 5000)\n",
            "End of epoch 57 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 58, iters: 84, time: 0.534, data: 0.008) D_A: 0.155 G_A: 0.036 cycle_A: 0.644 idt_A: 0.209 D_B: 0.206 G_B: 0.209 cycle_B: 0.457 idt_B: 0.261 \n",
            "End of epoch 58 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 59 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 60, iters: 8, time: 1.478, data: 0.002) D_A: 0.303 G_A: 0.125 cycle_A: 0.753 idt_A: 0.141 D_B: 0.298 G_B: 0.118 cycle_B: 0.355 idt_B: 0.392 \n",
            "saving the model at the end of epoch 60, iters 5280\n",
            "End of epoch 60 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 61, iters: 20, time: 0.534, data: 0.000) D_A: 0.426 G_A: 0.187 cycle_A: 0.611 idt_A: 0.207 D_B: 0.275 G_B: 0.692 cycle_B: 0.589 idt_B: 0.236 \n",
            "End of epoch 61 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 62, iters: 32, time: 0.527, data: 0.013) D_A: 0.040 G_A: 0.244 cycle_A: 0.777 idt_A: 0.292 D_B: 0.124 G_B: 0.597 cycle_B: 0.646 idt_B: 0.276 \n",
            "End of epoch 62 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 63, iters: 44, time: 0.520, data: 0.009) D_A: 0.083 G_A: 0.168 cycle_A: 0.479 idt_A: 0.139 D_B: 0.104 G_B: 0.204 cycle_B: 0.390 idt_B: 0.192 \n",
            "End of epoch 63 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 64, iters: 56, time: 1.176, data: 0.002) D_A: 0.403 G_A: 0.994 cycle_A: 1.955 idt_A: 0.163 D_B: 0.203 G_B: 0.317 cycle_B: 0.386 idt_B: 0.901 \n",
            "End of epoch 64 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 65, iters: 68, time: 0.531, data: 0.002) D_A: 0.189 G_A: 0.188 cycle_A: 0.937 idt_A: 0.193 D_B: 0.182 G_B: 0.038 cycle_B: 0.466 idt_B: 0.393 \n",
            "saving the model at the end of epoch 65, iters 5720\n",
            "End of epoch 65 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 66, iters: 80, time: 0.530, data: 0.003) D_A: 0.142 G_A: 0.475 cycle_A: 0.776 idt_A: 0.224 D_B: 0.341 G_B: 0.582 cycle_B: 0.545 idt_B: 0.285 \n",
            "End of epoch 66 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 67 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 68, iters: 4, time: 0.537, data: 0.002) D_A: 0.094 G_A: 0.276 cycle_A: 0.582 idt_A: 0.304 D_B: 0.121 G_B: 0.409 cycle_B: 0.770 idt_B: 0.246 \n",
            "End of epoch 68 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 69, iters: 16, time: 1.215, data: 0.000) D_A: 0.172 G_A: 0.683 cycle_A: 0.816 idt_A: 0.287 D_B: 0.057 G_B: 0.304 cycle_B: 0.561 idt_B: 0.354 \n",
            "End of epoch 69 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 70, iters: 28, time: 0.533, data: 0.002) D_A: 0.187 G_A: 0.270 cycle_A: 0.913 idt_A: 0.239 D_B: 0.132 G_B: 0.590 cycle_B: 0.598 idt_B: 0.365 \n",
            "saving the model at the end of epoch 70, iters 6160\n",
            "End of epoch 70 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 71, iters: 40, time: 0.530, data: 0.002) D_A: 0.239 G_A: 0.363 cycle_A: 0.728 idt_A: 0.151 D_B: 0.178 G_B: 0.517 cycle_B: 0.402 idt_B: 0.321 \n",
            "End of epoch 71 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 72, iters: 52, time: 0.534, data: 0.002) D_A: 0.171 G_A: 0.551 cycle_A: 1.001 idt_A: 0.254 D_B: 0.222 G_B: 0.199 cycle_B: 0.634 idt_B: 0.382 \n",
            "End of epoch 72 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 73, iters: 64, time: 1.263, data: 0.002) D_A: 0.229 G_A: 0.278 cycle_A: 1.198 idt_A: 0.229 D_B: 0.535 G_B: 0.532 cycle_B: 0.568 idt_B: 0.626 \n",
            "End of epoch 73 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 74, iters: 76, time: 0.533, data: 0.002) D_A: 0.234 G_A: 0.185 cycle_A: 0.722 idt_A: 0.270 D_B: 0.348 G_B: 0.397 cycle_B: 0.623 idt_B: 0.312 \n",
            "End of epoch 74 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 75, iters: 88, time: 0.533, data: 0.002) D_A: 0.121 G_A: 0.239 cycle_A: 0.459 idt_A: 0.129 D_B: 0.259 G_B: 0.234 cycle_B: 0.336 idt_B: 0.204 \n",
            "saving the model at the end of epoch 75, iters 6600\n",
            "End of epoch 75 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 76 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 77, iters: 12, time: 0.533, data: 0.141) D_A: 0.157 G_A: 0.429 cycle_A: 0.696 idt_A: 0.400 D_B: 0.279 G_B: 0.217 cycle_B: 0.868 idt_B: 0.315 \n",
            "End of epoch 77 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 78, iters: 24, time: 1.371, data: 0.002) D_A: 0.254 G_A: 0.473 cycle_A: 0.834 idt_A: 0.188 D_B: 0.251 G_B: 0.275 cycle_B: 0.426 idt_B: 0.389 \n",
            "End of epoch 78 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 79, iters: 36, time: 0.533, data: 0.002) D_A: 0.250 G_A: 0.246 cycle_A: 0.657 idt_A: 0.300 D_B: 0.267 G_B: 0.188 cycle_B: 0.635 idt_B: 0.286 \n",
            "End of epoch 79 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 80, iters: 48, time: 0.523, data: 0.002) D_A: 0.335 G_A: 0.453 cycle_A: 0.636 idt_A: 0.181 D_B: 0.263 G_B: 0.301 cycle_B: 0.433 idt_B: 0.229 \n",
            "saving the model at the end of epoch 80, iters 7040\n",
            "End of epoch 80 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 81, iters: 60, time: 0.534, data: 0.002) D_A: 0.155 G_A: 0.721 cycle_A: 0.537 idt_A: 0.328 D_B: 0.258 G_B: 0.216 cycle_B: 0.628 idt_B: 0.253 \n",
            "End of epoch 81 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 82, iters: 72, time: 1.306, data: 0.002) D_A: 0.205 G_A: 0.170 cycle_A: 0.825 idt_A: 0.180 D_B: 0.249 G_B: 0.244 cycle_B: 0.378 idt_B: 0.273 \n",
            "End of epoch 82 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 83, iters: 84, time: 0.530, data: 0.002) D_A: 0.283 G_A: 0.124 cycle_A: 0.664 idt_A: 0.149 D_B: 0.255 G_B: 0.280 cycle_B: 0.347 idt_B: 0.299 \n",
            "End of epoch 83 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 84 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 85, iters: 8, time: 0.530, data: 0.002) D_A: 0.144 G_A: 0.679 cycle_A: 0.475 idt_A: 0.169 D_B: 0.256 G_B: 0.264 cycle_B: 0.327 idt_B: 0.165 \n",
            "saving the model at the end of epoch 85, iters 7480\n",
            "End of epoch 85 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 86, iters: 20, time: 0.529, data: 0.000) D_A: 0.359 G_A: 0.141 cycle_A: 0.574 idt_A: 0.219 D_B: 0.254 G_B: 0.228 cycle_B: 0.473 idt_B: 0.247 \n",
            "End of epoch 86 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 87, iters: 32, time: 1.331, data: 0.002) D_A: 0.284 G_A: 0.148 cycle_A: 0.484 idt_A: 0.151 D_B: 0.261 G_B: 0.290 cycle_B: 0.320 idt_B: 0.207 \n",
            "End of epoch 87 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 88, iters: 44, time: 0.530, data: 0.002) D_A: 0.116 G_A: 0.385 cycle_A: 0.822 idt_A: 0.229 D_B: 0.242 G_B: 0.305 cycle_B: 0.554 idt_B: 0.381 \n",
            "End of epoch 88 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 89, iters: 56, time: 0.535, data: 0.002) D_A: 0.285 G_A: 0.419 cycle_A: 0.583 idt_A: 0.213 D_B: 0.250 G_B: 0.258 cycle_B: 0.478 idt_B: 0.274 \n",
            "End of epoch 89 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 90, iters: 68, time: 0.529, data: 0.002) D_A: 0.074 G_A: 0.536 cycle_A: 0.471 idt_A: 0.151 D_B: 0.239 G_B: 0.289 cycle_B: 0.343 idt_B: 0.183 \n",
            "saving the model at the end of epoch 90, iters 7920\n",
            "End of epoch 90 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 91, iters: 80, time: 1.387, data: 0.002) D_A: 0.110 G_A: 0.495 cycle_A: 1.018 idt_A: 0.222 D_B: 0.242 G_B: 0.256 cycle_B: 0.500 idt_B: 0.486 \n",
            "End of epoch 91 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 92 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 93, iters: 4, time: 0.537, data: 0.002) D_A: 0.193 G_A: 0.184 cycle_A: 0.514 idt_A: 0.288 D_B: 0.262 G_B: 0.213 cycle_B: 0.641 idt_B: 0.220 \n",
            "End of epoch 93 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 94, iters: 16, time: 0.534, data: 0.001) D_A: 0.208 G_A: 0.426 cycle_A: 0.635 idt_A: 0.196 D_B: 0.297 G_B: 0.317 cycle_B: 0.436 idt_B: 0.251 \n",
            "End of epoch 94 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 95, iters: 28, time: 0.528, data: 0.002) D_A: 0.091 G_A: 0.546 cycle_A: 0.557 idt_A: 0.118 D_B: 0.247 G_B: 0.261 cycle_B: 0.279 idt_B: 0.201 \n",
            "saving the model at the end of epoch 95, iters 8360\n",
            "End of epoch 95 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 96, iters: 40, time: 1.350, data: 0.002) D_A: 0.209 G_A: 0.199 cycle_A: 0.485 idt_A: 0.224 D_B: 0.236 G_B: 0.256 cycle_B: 0.434 idt_B: 0.216 \n",
            "End of epoch 96 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 97, iters: 52, time: 0.535, data: 0.002) D_A: 0.055 G_A: 0.149 cycle_A: 1.253 idt_A: 0.274 D_B: 0.262 G_B: 0.224 cycle_B: 0.611 idt_B: 0.561 \n",
            "End of epoch 97 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 98, iters: 64, time: 0.530, data: 0.002) D_A: 0.134 G_A: 0.216 cycle_A: 0.560 idt_A: 0.152 D_B: 0.317 G_B: 0.237 cycle_B: 0.331 idt_B: 0.179 \n",
            "End of epoch 98 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 99, iters: 76, time: 0.531, data: 0.002) D_A: 0.270 G_A: 0.261 cycle_A: 0.573 idt_A: 0.288 D_B: 0.242 G_B: 0.223 cycle_B: 0.699 idt_B: 0.249 \n",
            "End of epoch 99 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0002000 -> 0.0001980\n",
            "(epoch: 100, iters: 88, time: 1.382, data: 0.004) D_A: 0.227 G_A: 0.463 cycle_A: 0.604 idt_A: 0.201 D_B: 0.281 G_B: 0.211 cycle_B: 0.495 idt_B: 0.217 \n",
            "saving the model at the end of epoch 100, iters 8800\n",
            "End of epoch 100 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0001980 -> 0.0001960\n",
            "End of epoch 101 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001960 -> 0.0001941\n",
            "(epoch: 102, iters: 12, time: 0.534, data: 0.162) D_A: 0.469 G_A: 0.034 cycle_A: 0.496 idt_A: 0.409 D_B: 0.302 G_B: 0.382 cycle_B: 0.900 idt_B: 0.201 \n",
            "End of epoch 102 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001941 -> 0.0001921\n",
            "(epoch: 103, iters: 24, time: 0.531, data: 0.002) D_A: 0.094 G_A: 0.304 cycle_A: 1.142 idt_A: 0.206 D_B: 0.247 G_B: 0.254 cycle_B: 0.464 idt_B: 0.503 \n",
            "End of epoch 103 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001921 -> 0.0001901\n",
            "(epoch: 104, iters: 36, time: 0.529, data: 0.013) D_A: 0.335 G_A: 1.079 cycle_A: 0.515 idt_A: 0.161 D_B: 0.256 G_B: 0.244 cycle_B: 0.348 idt_B: 0.221 \n",
            "End of epoch 104 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001901 -> 0.0001881\n",
            "(epoch: 105, iters: 48, time: 1.480, data: 0.002) D_A: 0.267 G_A: 1.026 cycle_A: 0.679 idt_A: 0.205 D_B: 0.272 G_B: 0.278 cycle_B: 0.474 idt_B: 0.222 \n",
            "saving the model at the end of epoch 105, iters 9240\n",
            "End of epoch 105 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0001881 -> 0.0001861\n",
            "(epoch: 106, iters: 60, time: 0.534, data: 0.003) D_A: 0.248 G_A: 0.317 cycle_A: 0.693 idt_A: 0.171 D_B: 0.290 G_B: 0.368 cycle_B: 0.358 idt_B: 0.232 \n",
            "End of epoch 106 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001861 -> 0.0001842\n",
            "(epoch: 107, iters: 72, time: 0.534, data: 0.002) D_A: 0.048 G_A: 0.538 cycle_A: 0.541 idt_A: 0.172 D_B: 0.287 G_B: 0.162 cycle_B: 0.503 idt_B: 0.189 \n",
            "End of epoch 107 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001842 -> 0.0001822\n",
            "(epoch: 108, iters: 84, time: 0.532, data: 0.002) D_A: 0.117 G_A: 0.315 cycle_A: 0.683 idt_A: 0.211 D_B: 0.282 G_B: 0.325 cycle_B: 0.414 idt_B: 0.247 \n",
            "End of epoch 108 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001822 -> 0.0001802\n",
            "End of epoch 109 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001802 -> 0.0001782\n",
            "(epoch: 110, iters: 8, time: 1.387, data: 0.002) D_A: 0.179 G_A: 0.577 cycle_A: 1.049 idt_A: 0.182 D_B: 0.268 G_B: 0.328 cycle_B: 0.479 idt_B: 0.480 \n",
            "saving the model at the end of epoch 110, iters 9680\n",
            "End of epoch 110 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0001782 -> 0.0001762\n",
            "(epoch: 111, iters: 20, time: 0.535, data: 0.001) D_A: 0.179 G_A: 0.678 cycle_A: 0.460 idt_A: 0.135 D_B: 0.260 G_B: 0.296 cycle_B: 0.330 idt_B: 0.174 \n",
            "End of epoch 111 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001762 -> 0.0001743\n",
            "(epoch: 112, iters: 32, time: 0.531, data: 0.002) D_A: 0.151 G_A: 0.762 cycle_A: 0.516 idt_A: 0.142 D_B: 0.249 G_B: 0.224 cycle_B: 0.334 idt_B: 0.197 \n",
            "End of epoch 112 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001743 -> 0.0001723\n",
            "(epoch: 113, iters: 44, time: 0.532, data: 0.002) D_A: 0.351 G_A: 0.043 cycle_A: 0.448 idt_A: 0.134 D_B: 0.270 G_B: 0.414 cycle_B: 0.336 idt_B: 0.195 \n",
            "End of epoch 113 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001723 -> 0.0001703\n",
            "(epoch: 114, iters: 56, time: 1.526, data: 0.002) D_A: 0.066 G_A: 0.338 cycle_A: 0.427 idt_A: 0.174 D_B: 0.226 G_B: 0.425 cycle_B: 0.433 idt_B: 0.143 \n",
            "saving the latest model (epoch 114, total_iters 10000)\n",
            "End of epoch 114 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0001703 -> 0.0001683\n",
            "(epoch: 115, iters: 68, time: 0.534, data: 0.005) D_A: 0.093 G_A: 0.282 cycle_A: 0.642 idt_A: 0.326 D_B: 0.278 G_B: 0.176 cycle_B: 0.668 idt_B: 0.296 \n",
            "saving the model at the end of epoch 115, iters 10120\n",
            "End of epoch 115 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001683 -> 0.0001663\n",
            "(epoch: 116, iters: 80, time: 0.533, data: 0.002) D_A: 0.467 G_A: 0.025 cycle_A: 0.536 idt_A: 0.213 D_B: 0.255 G_B: 0.423 cycle_B: 0.461 idt_B: 0.210 \n",
            "End of epoch 116 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001663 -> 0.0001644\n",
            "End of epoch 117 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001644 -> 0.0001624\n",
            "(epoch: 118, iters: 4, time: 0.530, data: 0.002) D_A: 0.223 G_A: 1.070 cycle_A: 0.500 idt_A: 0.181 D_B: 0.247 G_B: 0.272 cycle_B: 0.412 idt_B: 0.193 \n",
            "End of epoch 118 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001624 -> 0.0001604\n",
            "(epoch: 119, iters: 16, time: 1.472, data: 0.000) D_A: 0.020 G_A: 0.477 cycle_A: 0.470 idt_A: 0.218 D_B: 0.270 G_B: 0.178 cycle_B: 0.504 idt_B: 0.162 \n",
            "End of epoch 119 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001604 -> 0.0001584\n",
            "(epoch: 120, iters: 28, time: 0.532, data: 0.003) D_A: 0.249 G_A: 0.625 cycle_A: 0.478 idt_A: 0.147 D_B: 0.228 G_B: 0.223 cycle_B: 0.304 idt_B: 0.202 \n",
            "saving the model at the end of epoch 120, iters 10560\n",
            "End of epoch 120 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001584 -> 0.0001564\n",
            "(epoch: 121, iters: 40, time: 0.534, data: 0.002) D_A: 0.277 G_A: 0.963 cycle_A: 0.476 idt_A: 0.129 D_B: 0.303 G_B: 0.256 cycle_B: 0.300 idt_B: 0.183 \n",
            "End of epoch 121 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001564 -> 0.0001545\n",
            "(epoch: 122, iters: 52, time: 0.533, data: 0.002) D_A: 0.152 G_A: 0.407 cycle_A: 0.481 idt_A: 0.132 D_B: 0.237 G_B: 0.287 cycle_B: 0.312 idt_B: 0.194 \n",
            "End of epoch 122 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001545 -> 0.0001525\n",
            "(epoch: 123, iters: 64, time: 1.526, data: 0.002) D_A: 0.041 G_A: 0.715 cycle_A: 1.241 idt_A: 0.178 D_B: 0.254 G_B: 0.322 cycle_B: 0.453 idt_B: 0.260 \n",
            "End of epoch 123 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001525 -> 0.0001505\n",
            "(epoch: 124, iters: 76, time: 0.533, data: 0.002) D_A: 0.403 G_A: 0.027 cycle_A: 0.457 idt_A: 0.162 D_B: 0.250 G_B: 0.382 cycle_B: 0.362 idt_B: 0.200 \n",
            "End of epoch 124 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001505 -> 0.0001485\n",
            "(epoch: 125, iters: 88, time: 0.531, data: 0.002) D_A: 0.025 G_A: 0.260 cycle_A: 0.410 idt_A: 0.203 D_B: 0.275 G_B: 0.180 cycle_B: 0.449 idt_B: 0.198 \n",
            "saving the model at the end of epoch 125, iters 11000\n",
            "End of epoch 125 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001485 -> 0.0001465\n",
            "End of epoch 126 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001465 -> 0.0001446\n",
            "(epoch: 127, iters: 12, time: 0.531, data: 0.138) D_A: 0.190 G_A: 0.219 cycle_A: 0.500 idt_A: 0.124 D_B: 0.260 G_B: 0.506 cycle_B: 0.315 idt_B: 0.213 \n",
            "End of epoch 127 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001446 -> 0.0001426\n",
            "(epoch: 128, iters: 24, time: 1.631, data: 0.002) D_A: 0.030 G_A: 0.789 cycle_A: 0.543 idt_A: 0.183 D_B: 0.239 G_B: 0.305 cycle_B: 0.407 idt_B: 0.186 \n",
            "End of epoch 128 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001426 -> 0.0001406\n",
            "(epoch: 129, iters: 36, time: 0.536, data: 0.005) D_A: 0.064 G_A: 0.649 cycle_A: 0.493 idt_A: 0.132 D_B: 0.202 G_B: 0.432 cycle_B: 0.332 idt_B: 0.194 \n",
            "End of epoch 129 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001406 -> 0.0001386\n",
            "(epoch: 130, iters: 48, time: 0.517, data: 0.004) D_A: 0.146 G_A: 0.286 cycle_A: 0.440 idt_A: 0.192 D_B: 0.247 G_B: 0.288 cycle_B: 0.469 idt_B: 0.184 \n",
            "saving the model at the end of epoch 130, iters 11440\n",
            "End of epoch 130 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001386 -> 0.0001366\n",
            "(epoch: 131, iters: 60, time: 0.524, data: 0.002) D_A: 0.114 G_A: 0.099 cycle_A: 0.498 idt_A: 0.109 D_B: 0.280 G_B: 0.194 cycle_B: 0.288 idt_B: 0.227 \n",
            "End of epoch 131 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001366 -> 0.0001347\n",
            "(epoch: 132, iters: 72, time: 1.556, data: 0.002) D_A: 0.186 G_A: 0.214 cycle_A: 0.541 idt_A: 0.270 D_B: 0.249 G_B: 0.333 cycle_B: 0.683 idt_B: 0.224 \n",
            "End of epoch 132 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001347 -> 0.0001327\n",
            "(epoch: 133, iters: 84, time: 0.533, data: 0.002) D_A: 0.083 G_A: 0.155 cycle_A: 1.257 idt_A: 0.148 D_B: 0.229 G_B: 0.217 cycle_B: 0.473 idt_B: 0.320 \n",
            "End of epoch 133 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001327 -> 0.0001307\n",
            "End of epoch 134 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001307 -> 0.0001287\n",
            "(epoch: 135, iters: 8, time: 0.532, data: 0.002) D_A: 0.087 G_A: 1.274 cycle_A: 0.756 idt_A: 0.124 D_B: 0.214 G_B: 0.096 cycle_B: 0.342 idt_B: 0.314 \n",
            "saving the model at the end of epoch 135, iters 11880\n",
            "End of epoch 135 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001287 -> 0.0001267\n",
            "(epoch: 136, iters: 20, time: 0.536, data: 0.002) D_A: 0.227 G_A: 0.179 cycle_A: 0.917 idt_A: 0.125 D_B: 0.201 G_B: 0.236 cycle_B: 0.329 idt_B: 0.276 \n",
            "End of epoch 136 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001267 -> 0.0001248\n",
            "(epoch: 137, iters: 32, time: 1.923, data: 0.002) D_A: 0.158 G_A: 0.239 cycle_A: 0.658 idt_A: 0.127 D_B: 0.107 G_B: 0.721 cycle_B: 0.317 idt_B: 0.219 \n",
            "End of epoch 137 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0001248 -> 0.0001228\n",
            "(epoch: 138, iters: 44, time: 0.531, data: 0.002) D_A: 0.223 G_A: 0.333 cycle_A: 0.433 idt_A: 0.164 D_B: 0.288 G_B: 0.811 cycle_B: 0.406 idt_B: 0.150 \n",
            "End of epoch 138 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001228 -> 0.0001208\n",
            "(epoch: 139, iters: 56, time: 0.520, data: 0.002) D_A: 0.197 G_A: 0.359 cycle_A: 0.586 idt_A: 0.206 D_B: 0.322 G_B: 0.081 cycle_B: 0.588 idt_B: 0.266 \n",
            "End of epoch 139 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001208 -> 0.0001188\n",
            "(epoch: 140, iters: 68, time: 0.527, data: 0.008) D_A: 0.268 G_A: 0.114 cycle_A: 0.509 idt_A: 0.173 D_B: 0.110 G_B: 0.642 cycle_B: 0.422 idt_B: 0.193 \n",
            "saving the model at the end of epoch 140, iters 12320\n",
            "End of epoch 140 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001188 -> 0.0001168\n",
            "(epoch: 141, iters: 80, time: 1.860, data: 0.002) D_A: 0.201 G_A: 0.325 cycle_A: 0.767 idt_A: 0.208 D_B: 0.824 G_B: 0.511 cycle_B: 0.574 idt_B: 0.281 \n",
            "End of epoch 141 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0001168 -> 0.0001149\n",
            "End of epoch 142 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001149 -> 0.0001129\n",
            "(epoch: 143, iters: 4, time: 0.524, data: 0.002) D_A: 0.093 G_A: 0.498 cycle_A: 0.461 idt_A: 0.108 D_B: 0.229 G_B: 0.491 cycle_B: 0.281 idt_B: 0.190 \n",
            "End of epoch 143 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001129 -> 0.0001109\n",
            "(epoch: 144, iters: 16, time: 0.524, data: 0.013) D_A: 0.120 G_A: 0.402 cycle_A: 0.473 idt_A: 0.181 D_B: 0.405 G_B: 0.066 cycle_B: 0.448 idt_B: 0.190 \n",
            "End of epoch 144 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001109 -> 0.0001089\n",
            "(epoch: 145, iters: 28, time: 0.526, data: 0.008) D_A: 0.180 G_A: 0.899 cycle_A: 0.685 idt_A: 0.108 D_B: 0.297 G_B: 0.404 cycle_B: 0.280 idt_B: 0.264 \n",
            "saving the model at the end of epoch 145, iters 12760\n",
            "End of epoch 145 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001089 -> 0.0001069\n",
            "(epoch: 146, iters: 40, time: 2.066, data: 0.014) D_A: 0.238 G_A: 0.421 cycle_A: 0.614 idt_A: 0.158 D_B: 0.253 G_B: 0.242 cycle_B: 0.377 idt_B: 0.248 \n",
            "End of epoch 146 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0001069 -> 0.0001050\n",
            "(epoch: 147, iters: 52, time: 0.524, data: 0.008) D_A: 0.035 G_A: 0.388 cycle_A: 0.529 idt_A: 0.165 D_B: 0.104 G_B: 0.526 cycle_B: 0.398 idt_B: 0.222 \n",
            "End of epoch 147 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0001050 -> 0.0001030\n",
            "(epoch: 148, iters: 64, time: 0.527, data: 0.014) D_A: 0.027 G_A: 0.248 cycle_A: 0.517 idt_A: 0.123 D_B: 0.521 G_B: 0.406 cycle_B: 0.323 idt_B: 0.207 \n",
            "End of epoch 148 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001030 -> 0.0001010\n",
            "(epoch: 149, iters: 76, time: 0.520, data: 0.010) D_A: 0.189 G_A: 0.644 cycle_A: 0.469 idt_A: 0.150 D_B: 0.187 G_B: 0.818 cycle_B: 0.411 idt_B: 0.190 \n",
            "End of epoch 149 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0001010 -> 0.0000990\n",
            "(epoch: 150, iters: 88, time: 1.952, data: 0.002) D_A: 0.023 G_A: 0.282 cycle_A: 0.575 idt_A: 0.313 D_B: 0.161 G_B: 0.778 cycle_B: 0.767 idt_B: 0.233 \n",
            "saving the model at the end of epoch 150, iters 13200\n",
            "End of epoch 150 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000990 -> 0.0000970\n",
            "End of epoch 151 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000970 -> 0.0000950\n",
            "(epoch: 152, iters: 12, time: 0.536, data: 0.184) D_A: 0.018 G_A: 0.426 cycle_A: 0.567 idt_A: 0.123 D_B: 0.138 G_B: 0.385 cycle_B: 0.304 idt_B: 0.229 \n",
            "End of epoch 152 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000950 -> 0.0000931\n",
            "(epoch: 153, iters: 24, time: 0.531, data: 0.002) D_A: 0.079 G_A: 0.392 cycle_A: 0.502 idt_A: 0.144 D_B: 0.265 G_B: 0.165 cycle_B: 0.366 idt_B: 0.191 \n",
            "End of epoch 153 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000931 -> 0.0000911\n",
            "(epoch: 154, iters: 36, time: 0.523, data: 0.009) D_A: 0.072 G_A: 0.491 cycle_A: 0.482 idt_A: 0.176 D_B: 0.151 G_B: 0.526 cycle_B: 0.449 idt_B: 0.186 \n",
            "End of epoch 154 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000911 -> 0.0000891\n",
            "(epoch: 155, iters: 48, time: 2.167, data: 0.012) D_A: 0.272 G_A: 0.069 cycle_A: 0.418 idt_A: 0.204 D_B: 0.169 G_B: 0.299 cycle_B: 0.445 idt_B: 0.165 \n",
            "saving the model at the end of epoch 155, iters 13640\n",
            "End of epoch 155 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000891 -> 0.0000871\n",
            "(epoch: 156, iters: 60, time: 0.526, data: 0.009) D_A: 0.059 G_A: 0.258 cycle_A: 0.487 idt_A: 0.165 D_B: 0.223 G_B: 0.435 cycle_B: 0.413 idt_B: 0.174 \n",
            "End of epoch 156 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000871 -> 0.0000851\n",
            "(epoch: 157, iters: 72, time: 0.525, data: 0.009) D_A: 0.041 G_A: 1.035 cycle_A: 0.736 idt_A: 0.144 D_B: 0.228 G_B: 0.304 cycle_B: 0.421 idt_B: 0.276 \n",
            "End of epoch 157 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000851 -> 0.0000832\n",
            "(epoch: 158, iters: 84, time: 0.526, data: 0.004) D_A: 0.103 G_A: 0.263 cycle_A: 0.384 idt_A: 0.144 D_B: 0.190 G_B: 0.178 cycle_B: 0.357 idt_B: 0.129 \n",
            "End of epoch 158 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000832 -> 0.0000812\n",
            "End of epoch 159 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000812 -> 0.0000792\n",
            "(epoch: 160, iters: 8, time: 2.022, data: 0.002) D_A: 0.189 G_A: 0.891 cycle_A: 0.438 idt_A: 0.132 D_B: 0.225 G_B: 0.134 cycle_B: 0.311 idt_B: 0.154 \n",
            "saving the model at the end of epoch 160, iters 14080\n",
            "End of epoch 160 / 200 \t Time Taken: 46 sec\n",
            "learning rate 0.0000792 -> 0.0000772\n",
            "(epoch: 161, iters: 20, time: 0.522, data: 0.001) D_A: 0.209 G_A: 0.168 cycle_A: 0.525 idt_A: 0.189 D_B: 0.236 G_B: 0.293 cycle_B: 0.465 idt_B: 0.219 \n",
            "End of epoch 161 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000772 -> 0.0000752\n",
            "(epoch: 162, iters: 32, time: 0.522, data: 0.009) D_A: 0.049 G_A: 0.615 cycle_A: 0.526 idt_A: 0.102 D_B: 0.449 G_B: 0.309 cycle_B: 0.298 idt_B: 0.193 \n",
            "End of epoch 162 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000752 -> 0.0000733\n",
            "(epoch: 163, iters: 44, time: 0.525, data: 0.013) D_A: 0.102 G_A: 0.366 cycle_A: 0.523 idt_A: 0.132 D_B: 0.088 G_B: 0.563 cycle_B: 0.356 idt_B: 0.187 \n",
            "End of epoch 163 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000733 -> 0.0000713\n",
            "(epoch: 164, iters: 56, time: 2.113, data: 0.013) D_A: 0.056 G_A: 0.268 cycle_A: 0.603 idt_A: 0.177 D_B: 0.031 G_B: 0.597 cycle_B: 0.464 idt_B: 0.246 \n",
            "End of epoch 164 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000713 -> 0.0000693\n",
            "(epoch: 165, iters: 68, time: 0.527, data: 0.008) D_A: 0.059 G_A: 0.238 cycle_A: 0.491 idt_A: 0.151 D_B: 0.145 G_B: 0.429 cycle_B: 0.410 idt_B: 0.174 \n",
            "saving the model at the end of epoch 165, iters 14520\n",
            "End of epoch 165 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000693 -> 0.0000673\n",
            "(epoch: 166, iters: 80, time: 0.525, data: 0.008) D_A: 0.026 G_A: 0.285 cycle_A: 0.489 idt_A: 0.141 D_B: 0.237 G_B: 0.525 cycle_B: 0.393 idt_B: 0.162 \n",
            "End of epoch 166 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000673 -> 0.0000653\n",
            "End of epoch 167 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000653 -> 0.0000634\n",
            "(epoch: 168, iters: 4, time: 0.524, data: 0.002) D_A: 0.102 G_A: 0.617 cycle_A: 0.416 idt_A: 0.215 D_B: 0.156 G_B: 0.424 cycle_B: 0.507 idt_B: 0.173 \n",
            "End of epoch 168 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000634 -> 0.0000614\n",
            "(epoch: 169, iters: 16, time: 2.154, data: 0.010) D_A: 0.251 G_A: 0.284 cycle_A: 0.508 idt_A: 0.168 D_B: 0.118 G_B: 0.500 cycle_B: 0.437 idt_B: 0.217 \n",
            "End of epoch 169 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000614 -> 0.0000594\n",
            "(epoch: 170, iters: 28, time: 0.527, data: 0.002) D_A: 0.187 G_A: 0.233 cycle_A: 0.398 idt_A: 0.135 D_B: 0.378 G_B: 0.410 cycle_B: 0.360 idt_B: 0.148 \n",
            "saving the model at the end of epoch 170, iters 14960\n",
            "End of epoch 170 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000594 -> 0.0000574\n",
            "(epoch: 171, iters: 40, time: 0.523, data: 0.010) D_A: 0.093 G_A: 0.239 cycle_A: 0.434 idt_A: 0.176 D_B: 0.103 G_B: 0.380 cycle_B: 0.488 idt_B: 0.194 \n",
            "saving the latest model (epoch 171, total_iters 15000)\n",
            "End of epoch 171 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000574 -> 0.0000554\n",
            "(epoch: 172, iters: 52, time: 0.527, data: 0.004) D_A: 0.153 G_A: 0.282 cycle_A: 0.569 idt_A: 0.108 D_B: 0.220 G_B: 0.536 cycle_B: 0.291 idt_B: 0.193 \n",
            "End of epoch 172 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000554 -> 0.0000535\n",
            "(epoch: 173, iters: 64, time: 1.808, data: 0.002) D_A: 0.099 G_A: 0.375 cycle_A: 0.386 idt_A: 0.162 D_B: 0.085 G_B: 0.444 cycle_B: 0.417 idt_B: 0.135 \n",
            "End of epoch 173 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000535 -> 0.0000515\n",
            "(epoch: 174, iters: 76, time: 0.522, data: 0.009) D_A: 0.107 G_A: 0.522 cycle_A: 0.601 idt_A: 0.106 D_B: 0.061 G_B: 0.331 cycle_B: 0.285 idt_B: 0.188 \n",
            "End of epoch 174 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000515 -> 0.0000495\n",
            "(epoch: 175, iters: 88, time: 0.529, data: 0.005) D_A: 0.161 G_A: 0.460 cycle_A: 0.588 idt_A: 0.121 D_B: 0.032 G_B: 0.886 cycle_B: 0.325 idt_B: 0.210 \n",
            "saving the model at the end of epoch 175, iters 15400\n",
            "End of epoch 175 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000495 -> 0.0000475\n",
            "End of epoch 176 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000475 -> 0.0000455\n",
            "(epoch: 177, iters: 12, time: 0.536, data: 0.181) D_A: 0.400 G_A: 0.042 cycle_A: 0.507 idt_A: 0.152 D_B: 0.021 G_B: 0.553 cycle_B: 0.462 idt_B: 0.201 \n",
            "End of epoch 177 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000455 -> 0.0000436\n",
            "(epoch: 178, iters: 24, time: 1.789, data: 0.002) D_A: 0.082 G_A: 0.400 cycle_A: 0.439 idt_A: 0.151 D_B: 0.047 G_B: 0.572 cycle_B: 0.442 idt_B: 0.175 \n",
            "End of epoch 178 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000436 -> 0.0000416\n",
            "(epoch: 179, iters: 36, time: 0.530, data: 0.002) D_A: 0.113 G_A: 0.320 cycle_A: 0.408 idt_A: 0.123 D_B: 0.117 G_B: 0.149 cycle_B: 0.357 idt_B: 0.171 \n",
            "End of epoch 179 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000416 -> 0.0000396\n",
            "(epoch: 180, iters: 48, time: 0.519, data: 0.002) D_A: 0.046 G_A: 0.349 cycle_A: 0.479 idt_A: 0.138 D_B: 0.216 G_B: 0.407 cycle_B: 0.378 idt_B: 0.184 \n",
            "saving the model at the end of epoch 180, iters 15840\n",
            "End of epoch 180 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000396 -> 0.0000376\n",
            "(epoch: 181, iters: 60, time: 0.531, data: 0.002) D_A: 0.246 G_A: 0.290 cycle_A: 0.479 idt_A: 0.208 D_B: 0.075 G_B: 0.255 cycle_B: 0.432 idt_B: 0.178 \n",
            "End of epoch 181 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000376 -> 0.0000356\n",
            "(epoch: 182, iters: 72, time: 1.759, data: 0.002) D_A: 0.109 G_A: 0.130 cycle_A: 0.654 idt_A: 0.125 D_B: 0.240 G_B: 0.243 cycle_B: 0.342 idt_B: 0.261 \n",
            "End of epoch 182 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000356 -> 0.0000337\n",
            "(epoch: 183, iters: 84, time: 0.536, data: 0.004) D_A: 0.071 G_A: 0.290 cycle_A: 0.530 idt_A: 0.126 D_B: 0.179 G_B: 0.297 cycle_B: 0.361 idt_B: 0.227 \n",
            "End of epoch 183 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000337 -> 0.0000317\n",
            "End of epoch 184 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000317 -> 0.0000297\n",
            "(epoch: 185, iters: 8, time: 0.536, data: 0.002) D_A: 0.046 G_A: 0.219 cycle_A: 0.427 idt_A: 0.157 D_B: 0.107 G_B: 0.569 cycle_B: 0.418 idt_B: 0.223 \n",
            "saving the model at the end of epoch 185, iters 16280\n",
            "End of epoch 185 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000297 -> 0.0000277\n",
            "(epoch: 186, iters: 20, time: 0.532, data: 0.002) D_A: 0.074 G_A: 0.472 cycle_A: 0.444 idt_A: 0.149 D_B: 0.195 G_B: 0.369 cycle_B: 0.433 idt_B: 0.160 \n",
            "End of epoch 186 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000277 -> 0.0000257\n",
            "(epoch: 187, iters: 32, time: 1.876, data: 0.002) D_A: 0.097 G_A: 0.471 cycle_A: 1.052 idt_A: 0.148 D_B: 0.134 G_B: 0.468 cycle_B: 0.359 idt_B: 0.407 \n",
            "End of epoch 187 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000257 -> 0.0000238\n",
            "(epoch: 188, iters: 44, time: 0.535, data: 0.002) D_A: 0.140 G_A: 0.307 cycle_A: 0.402 idt_A: 0.108 D_B: 0.136 G_B: 0.403 cycle_B: 0.311 idt_B: 0.175 \n",
            "End of epoch 188 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000238 -> 0.0000218\n",
            "(epoch: 189, iters: 56, time: 0.531, data: 0.002) D_A: 0.132 G_A: 0.325 cycle_A: 0.395 idt_A: 0.175 D_B: 0.129 G_B: 0.442 cycle_B: 0.485 idt_B: 0.166 \n",
            "End of epoch 189 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000218 -> 0.0000198\n",
            "(epoch: 190, iters: 68, time: 0.534, data: 0.006) D_A: 0.226 G_A: 0.342 cycle_A: 0.383 idt_A: 0.133 D_B: 0.185 G_B: 0.332 cycle_B: 0.387 idt_B: 0.155 \n",
            "saving the model at the end of epoch 190, iters 16720\n",
            "End of epoch 190 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000198 -> 0.0000178\n",
            "(epoch: 191, iters: 80, time: 2.024, data: 0.002) D_A: 0.140 G_A: 0.281 cycle_A: 0.377 idt_A: 0.129 D_B: 0.111 G_B: 0.306 cycle_B: 0.339 idt_B: 0.128 \n",
            "End of epoch 191 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000178 -> 0.0000158\n",
            "End of epoch 192 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000158 -> 0.0000139\n",
            "(epoch: 193, iters: 4, time: 0.538, data: 0.002) D_A: 0.036 G_A: 0.186 cycle_A: 0.335 idt_A: 0.137 D_B: 0.172 G_B: 0.298 cycle_B: 0.391 idt_B: 0.138 \n",
            "End of epoch 193 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000139 -> 0.0000119\n",
            "(epoch: 194, iters: 16, time: 0.533, data: 0.000) D_A: 0.154 G_A: 0.241 cycle_A: 0.427 idt_A: 0.181 D_B: 0.125 G_B: 0.366 cycle_B: 0.487 idt_B: 0.153 \n",
            "End of epoch 194 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000119 -> 0.0000099\n",
            "(epoch: 195, iters: 28, time: 0.535, data: 0.002) D_A: 0.150 G_A: 0.294 cycle_A: 0.510 idt_A: 0.115 D_B: 0.270 G_B: 0.200 cycle_B: 0.327 idt_B: 0.172 \n",
            "saving the model at the end of epoch 195, iters 17160\n",
            "End of epoch 195 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000099 -> 0.0000079\n",
            "(epoch: 196, iters: 40, time: 1.811, data: 0.004) D_A: 0.148 G_A: 0.409 cycle_A: 0.358 idt_A: 0.128 D_B: 0.241 G_B: 0.222 cycle_B: 0.362 idt_B: 0.133 \n",
            "End of epoch 196 / 200 \t Time Taken: 45 sec\n",
            "learning rate 0.0000079 -> 0.0000059\n",
            "(epoch: 197, iters: 52, time: 0.528, data: 0.005) D_A: 0.274 G_A: 0.283 cycle_A: 0.331 idt_A: 0.138 D_B: 0.154 G_B: 0.400 cycle_B: 0.386 idt_B: 0.128 \n",
            "End of epoch 197 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000059 -> 0.0000040\n",
            "(epoch: 198, iters: 64, time: 0.528, data: 0.002) D_A: 0.174 G_A: 0.444 cycle_A: 0.340 idt_A: 0.134 D_B: 0.227 G_B: 0.244 cycle_B: 0.330 idt_B: 0.127 \n",
            "End of epoch 198 / 200 \t Time Taken: 43 sec\n",
            "learning rate 0.0000040 -> 0.0000020\n",
            "(epoch: 199, iters: 76, time: 0.527, data: 0.002) D_A: 0.198 G_A: 0.354 cycle_A: 0.397 idt_A: 0.143 D_B: 0.144 G_B: 0.328 cycle_B: 0.368 idt_B: 0.138 \n",
            "End of epoch 199 / 200 \t Time Taken: 44 sec\n",
            "learning rate 0.0000020 -> 0.0000000\n",
            "(epoch: 200, iters: 88, time: 2.087, data: 0.012) D_A: 0.077 G_A: 0.434 cycle_A: 0.425 idt_A: 0.148 D_B: 0.135 G_B: 0.672 cycle_B: 0.448 idt_B: 0.169 \n",
            "saving the model at the end of epoch 200, iters 17600\n",
            "End of epoch 200 / 200 \t Time Taken: 46 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --dataroot ./datasets/photo2sketch/ --name ph2sk_cyclegan --model cycle_gan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnGSlO6_-W1C",
        "outputId": "d3509260-d7d1-49c3-9e7e-a9599f60d31d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
            "Warning: wandb package cannot be found. The option \"--use_wandb\" will result in error.\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/photo2sketch/      \t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cycle_gan                     \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: ph2sk_cyclegan                \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                     norm: instance                      \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [CycleGANModel] was created\n",
            "loading the model from ./checkpoints/ph2sk_cyclegan/latest_net_G_A.pth\n",
            "loading the model from ./checkpoints/ph2sk_cyclegan/latest_net_G_B.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 11.378 M\n",
            "[Network G_B] Total number of parameters : 11.378 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/ph2sk_cyclegan/test_latest\n",
            "processing (0000)-th image... ['./datasets/photo2sketch/testA/f-039-01.jpg']\n",
            "processing (0005)-th image... ['./datasets/photo2sketch/testA/f1-001-01.jpg']\n",
            "processing (0010)-th image... ['./datasets/photo2sketch/testA/f1-006-01.jpg']\n",
            "processing (0015)-th image... ['./datasets/photo2sketch/testA/f1-011-01.jpg']\n",
            "processing (0020)-th image... ['./datasets/photo2sketch/testA/m-063-01.jpg']\n",
            "processing (0025)-th image... ['./datasets/photo2sketch/testA/m-068-01.jpg']\n",
            "processing (0030)-th image... ['./datasets/photo2sketch/testA/m-073-01.jpg']\n",
            "processing (0035)-th image... ['./datasets/photo2sketch/testA/m-078-01.jpg']\n",
            "processing (0040)-th image... ['./datasets/photo2sketch/testA/m-083-01.jpg']\n",
            "processing (0045)-th image... ['./datasets/photo2sketch/testA/m-088-01.jpg']\n"
          ]
        }
      ]
    }
  ]
}